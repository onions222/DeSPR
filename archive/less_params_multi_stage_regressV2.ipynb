{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†é˜¶æ®µå‚æ•°ä¼˜åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å·¥å…·å‡½æ•°å’Œæ ·æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import json\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "import numpy as np\n",
    "# ç¦ç”¨Optunaçš„æ—¥å¿—\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"plot_optimization_history is experimental .*\")\n",
    "\n",
    "samples = [\n",
    "    ((24, 56, 57, 55), (0, 56, 56)), ((11, 31, 33, 32), (0, 32, 32)),\n",
    "    ((28, 1, 31, 1), (32, 0, 32)), ((42, 3, 47, 3), (48, 0, 48)),\n",
    "    ((65, 7, 72, 7), (72, 0, 72)), ((72, 72, 17, 72), (72, 72, 0)),\n",
    "    ((56, 56, 11, 56), (56, 56, 0)), ((24, 24, 2, 24), (24, 24, 0)),\n",
    "    ((214, 213, 73, 214), (216, 216, 0)), ((245, 244, 85, 244), (248, 248, 0)),\n",
    "    ((137, 244, 246, 244), (0, 248, 248)), ((123, 221, 223, 221), (0, 224, 224)),\n",
    "    ((99, 182, 181, 181), (0, 184, 184)), ((67, 128, 130, 129),(0, 128, 128)),\n",
    "    ((29, 63, 65, 64), (0, 64, 64)), ((199, 46, 217, 47),(224, 0, 224)),\n",
    "    ((130, 26, 141, 26),(144, 0, 144)),((58, 5, 64, 6),(64, 0, 64)),\n",
    "    ((229, 230, 80, 230),(232, 232, 0)),((150, 150, 48, 150),(152, 152, 0)),\n",
    "    ((96, 96, 27, 96),(96 ,96 ,0)),\n",
    "    ((74, 63, 66, 62), (77, 62, 66)), ((89, 143, 92, 142), (49, 149, 90)), \n",
    "    ((108, 109, 206, 109), (97, 103, 219)), ((77, 96, 116, 95), (77, 96, 116)),\n",
    "    ((56, 77, 186, 76), (30, 73, 198)), ((201, 127, 62, 128), (230, 120, 40)),\n",
    "    ((209, 53, 80, 54), (239, 19, 70)), ((165, 37, 70, 38), (193, 0, 64)),\n",
    "    ((67, 131, 121, 132), (0, 131, 117)), ((130, 150, 47, 149), (121, 153, 0)),\n",
    "    ((128, 234, 135, 233), (0, 240, 118)), ((139, 219, 169, 218), (87, 223, 160)),\n",
    "    ((241, 239, 116, 238), (245, 240, 113)), ((216, 70, 82, 69), (248, 53, 71)),\n",
    "    ((169, 35, 70, 36), (193, 0, 64)), ((213, 162, 77, 161), (230, 160, 50)),\n",
    "    ((241, 205, 96, 204), (255, 205, 64)), ((130, 134, 246, 135), (120, 130, 255)),\n",
    "    ((81, 147, 194, 146), (11, 147, 197)), ((96, 136, 236, 135), (66, 134, 244)),\n",
    "    ((82, 153, 97, 154), (15, 157, 88)), ((85, 157, 103, 158), (22, 160, 93)),\n",
    "    ((198, 50, 144, 49),(225, 20, 145)), ((228,128,147,128),(253,118,144)),\n",
    "    ((207, 46, 141, 46),(236, 0, 140)), ((239, 195, 70, 194),(255, 193, 0)),\n",
    "    ((230, 149, 59, 148),(253, 145, 12)),((194, 79, 67, 79),(219, 68, 55)),\n",
    "    ((182, 39, 74, 38),(207, 0, 69)), ((106, 24, 72, 24),(117, 11, 70)),\n",
    "    ((135, 187, 239, 186), (101, 187, 244)), ((118, 113, 236, 113), (112, 108, 245)),\n",
    "    ((133, 164, 225, 163), (112, 164, 230)), ((149, 127, 218, 125),(152, 121, 224)),\n",
    "    ((80, 110, 208, 110),(56, 107, 215)), ((23, 49, 82, 49),(0, 49, 82)),\n",
    "    ((110, 200, 129, 200),(11, 205, 116)), ((93, 163, 182, 163),(31, 165, 183)),\n",
    "    ((89, 160, 108, 160), (30, 163, 98)), ((157, 194, 99, 192),(143, 197, 80))\n",
    "]\n",
    "\n",
    "# ---------- å·¥å…·å‡½æ•° ----------\n",
    "def save_best_params(trial, filename):\n",
    "    with open(filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"parameter\", \"value\"])\n",
    "        for k, v in trial.params.items():\n",
    "            writer.writerow([k, v])\n",
    "    with open(filename.replace(\".csv\", \".json\"), 'w') as f:\n",
    "        json.dump(trial.params, f, indent=2)\n",
    "\n",
    "def load_params_from_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def plot_history(study, stage_name):\n",
    "    fig = plot_optimization_history(study, target=lambda t: t.values[0], target_name=\"MAE\")\n",
    "    fig.figure.tight_layout()\n",
    "    # fig.figure.savefig(f\"{stage_name}_optimization_history.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pentile_to_rgb(R, G1, B, G2, params):\n",
    "    '''IDEAï¼šäººç±»è§†è§‰ä¸»è¦å—äº®åº¦å’Œè‰²åº¦çš„å½±å“ï¼Œä»Žå¤šä¸ªé€šé“çš„è§’åº¦è€ƒè™‘ï¼Œä¸»è¦å—ä¸»è¦é€šé“æ”¯é…'''\n",
    "    low_bound, mid_bound, close_threshold, enhance_coeffs, reduce_coeffs, thresholds, \\\n",
    "    R_params, G_params, B_params = params\n",
    "    G = (G1 + G2) >> 1\n",
    "    R_prime, G_prime, B_prime = R, G, B\n",
    "    values = [R, G, B]\n",
    "    sorted_vals = sorted(values, reverse=True)\n",
    "    max_val, second_val, _ = sorted_vals\n",
    "    idx = np.argsort(values)[::-1]\n",
    "    # fine tune coefficients\n",
    "    ft_G = [1/2, 3/8, 1/4] \n",
    "\n",
    "    if max_val - second_val < close_threshold:\n",
    "        if max_val <= low_bound:\n",
    "            enhance_coeff, reduce_coeff = enhance_coeffs[0], reduce_coeffs[0]\n",
    "        elif max_val <= mid_bound:\n",
    "            enhance_coeff, reduce_coeff = enhance_coeffs[1], reduce_coeffs[1]\n",
    "        else:\n",
    "            enhance_coeff, reduce_coeff = enhance_coeffs[2], reduce_coeffs[2]\n",
    "\n",
    "        if (idx[0], idx[1]) in [(0,1), (1,0)]:\n",
    "            R_prime = min(R + int(enhance_coeff * R), 255)\n",
    "            G_prime = min(G + int(enhance_coeff * G), 255)\n",
    "            B_prime = max(B - int(reduce_coeff * (max(R, G) - B)), 0)\n",
    "        elif (idx[0], idx[1]) in [(0,2), (2,0)]:\n",
    "            R_prime = min(R + int(enhance_coeff * R), 255)\n",
    "            B_prime = min(B + int(enhance_coeff * B), 255)\n",
    "            G_prime = max(G - int(reduce_coeff * (max(R, B) - G)), 0)\n",
    "        elif (idx[0], idx[1]) in [(1,2), (2,1)]:\n",
    "            G_prime = min(G + int(enhance_coeff * G), 255)\n",
    "            B_prime = min(B + int(enhance_coeff * B), 255)\n",
    "            R_prime = max(R - int(reduce_coeff * (max(G, B) - R)), 0)\n",
    "    else:\n",
    "        if idx[0] == 0:\n",
    "            B = B*1.1\n",
    "            if R < thresholds[0]:\n",
    "                R_prime = min(R + R_params[0], 255)\n",
    "                G_prime = max(G - 0.5*R_params[4]*(R-G), 0)\n",
    "                B_prime = max(B - R_params[4]*(R-B), 0)\n",
    "            elif R < thresholds[1]:\n",
    "                R_prime = min(R + int(R_params[1]*R), 255)\n",
    "                G_prime = max(G - ft_G[0]*int(R_params[5]*(R-G)), 0)\n",
    "                B_prime = max(B - int(R_params[5]*(R-B)), 0)\n",
    "            elif R < thresholds[2]:\n",
    "                R_prime = min(R + int(R_params[2]*R), 255)\n",
    "                G_prime = max(G - ft_G[1]*int(R_params[6]*(R-G)), 0)\n",
    "                B_prime = max(B - int(R_params[6]*(R-B)), 0)\n",
    "            else:\n",
    "                R_prime = min(R + int(R_params[3]*R), 255)\n",
    "                G_prime = max(G - ft_G[2]*int(R_params[7]*(R-G)), 0)\n",
    "                B_prime = max(B - int(R_params[7]*(R-B)), 0)\n",
    "        elif idx[0] == 1:\n",
    "            if G < thresholds[0]:\n",
    "                G_prime = min(G + G_params[0], 255)\n",
    "                R_prime = max(R - G_params[4]*(G-R), 0)\n",
    "                B_prime = max(B - G_params[4]*(G-B), 0)\n",
    "            elif G < thresholds[1]:\n",
    "                G_prime = min(G + int(G_params[1]*G), 255)\n",
    "                R_prime = max(R - int(G_params[5]*(G-R)), 0)\n",
    "                B_prime = max(B - int(G_params[5]*(G-B)), 0)\n",
    "            elif G < thresholds[2]:\n",
    "                G_prime = min(G + int(G_params[2]*G), 255)\n",
    "                R_prime = max(R - int(G_params[6]*(G-R)), 0)\n",
    "                B_prime = max(B - int(G_params[6]*(G-B)), 0)\n",
    "            else:\n",
    "                G_prime = min(G + int(G_params[3]*G), 255)\n",
    "                R_prime = max(R - int(G_params[7]*(G-R)), 0)\n",
    "                B_prime = max(B - int(G_params[7]*(G-B)), 0)\n",
    "        else:\n",
    "            R = R*1.1\n",
    "            if B < thresholds[0]:\n",
    "                B_prime = min(B + B_params[0], 255)\n",
    "                R_prime = max(R - B_params[4]*(B-R), 0)\n",
    "                G_prime = max(G - 0.5*B_params[4]*(B-G), 0)\n",
    "            elif B < thresholds[1]:\n",
    "                B_prime = min(B + int(B_params[1]*B), 255)\n",
    "                R_prime = max(R - int(B_params[5]*(B-R)), 0)\n",
    "                G_prime = max(G - ft_G[0]*int(B_params[5]*(B-G)), 0)\n",
    "            elif B < thresholds[2]:\n",
    "                B_prime = min(B + int(B_params[2]*B), 255)\n",
    "                R_prime = max(R - int(B_params[6]*(B-R)), 0)\n",
    "                G_prime = max(G - ft_G[1]*int(B_params[6]*(B-G)), 0)\n",
    "            else:\n",
    "                B_prime = min(B + int(B_params[3]*B), 255)\n",
    "                R_prime = max(R - int(B_params[7]*(B-R)), 0)\n",
    "                G_prime = max(G - ft_G[2]*int(B_params[7]*(B-G)), 0)\n",
    "\n",
    "    return int(R_prime), int(G_prime), (B_prime)\n",
    "\n",
    "\n",
    "def compute_mae_and_smoothness(params):\n",
    "    total_mae = 0\n",
    "    smoothness_score = 0\n",
    "    weighted_mae = 0\n",
    "    errors = []\n",
    "    max_weight = 8.0\n",
    "\n",
    "    for i, ((R, G1, B, G2), (R_target, G_target, B_target)) in enumerate(samples):\n",
    "        R_pred, G_pred, B_pred = pentile_to_rgb(R, G1, B, G2, params)\n",
    "        r_err = abs(R_pred - R_target)\n",
    "        g_err = abs(G_pred - G_target)\n",
    "        b_err = abs(B_pred - B_target)\n",
    "        mae = r_err + g_err + b_err\n",
    "        base_error = r_err + g_err + b_err\n",
    "        important_indices = [20, 37, 39, 31, 10, 11]\n",
    "        if i in important_indices:\n",
    "            base_error *= max_weight\n",
    "        errors.append(base_error)\n",
    "        total_mae += mae\n",
    "    n = len(samples)\n",
    "    max_error = max(errors)\n",
    "    weights = [np.exp(e / max_error) for e in errors]\n",
    "\n",
    "    for i, weight in enumerate(weights):\n",
    "        weighted_mae += errors[i] * weight\n",
    "\n",
    "    return weighted_mae / n\n",
    "\n",
    "\n",
    "def print_predictions(best_params):\n",
    "    thresholds = [\n",
    "        best_params[\"threshold0\"],\n",
    "        best_params[\"threshold1\"],\n",
    "        best_params[\"threshold2\"]\n",
    "    ]\n",
    "    enhance_coeffs = [best_params[f\"enhance{i}\"] for i in range(3)]\n",
    "    reduce_coeffs = [best_params[f\"reduce{i}\"] for i in range(3)]\n",
    "    R_params = [1] + [best_params[f\"R_enh{i+1}\"] for i in range(3)] + [best_params[f\"R_red{i+1}\"] for i in range(4)]\n",
    "    G_params = [1] + [best_params[f\"G_enh{i+1}\"] for i in range(3)] + [best_params[f\"G_red{i+1}\"] for i in range(4)]\n",
    "    B_params = [1] + [best_params[f\"B_enh{i+1}\"] for i in range(3)] + [best_params[f\"B_red{i+1}\"] for i in range(4)]\n",
    "    params = (\n",
    "        best_params[\"low_bound\"],\n",
    "        best_params[\"mid_bound\"],\n",
    "        best_params[\"close_threshold\"],\n",
    "        enhance_coeffs,\n",
    "        reduce_coeffs,\n",
    "        thresholds,\n",
    "        tuple(R_params), tuple(G_params), tuple(B_params)\n",
    "    )\n",
    "\n",
    "    total_R_error, total_G_error, total_B_error = 0, 0, 0\n",
    "    n = len(samples)\n",
    "    for (R, G1, B, G2), (R_target, G_target, B_target) in samples:\n",
    "        R_pred, G_pred, B_pred = pentile_to_rgb(R, G1, B, G2, params)\n",
    "        total_R_error += abs(R_pred - R_target)\n",
    "        total_G_error += abs(G_pred - G_target)\n",
    "        total_B_error += abs(B_pred - B_target)\n",
    "    mad_R = total_R_error / n\n",
    "    mad_G = total_G_error / n\n",
    "    mad_B = total_B_error / n\n",
    "    overall_mad = (mad_R + mad_G + mad_B) / 3\n",
    "    print(f\"\\nAverage MAD: R = {mad_R:.2f}, G = {mad_G:.2f}, B = {mad_B:.2f}, Overall = {overall_mad:.2f}\")\n",
    "\n",
    "    print(\"\\nSample predictions:\")\n",
    "    for i, ((R, G1, B, G2), (RT, GT, BT)) in enumerate(samples):\n",
    "        R_pred, G_pred, B_pred = pentile_to_rgb(R, G1, B, G2, params)\n",
    "        print(f\"Sample {i+1}: input = ({(R, G1, B, G2)}), Predicted = ({R_pred}, {G_pred}, {B_pred}), Target = ({RT}, {GT}, {BT}), Î” = ({abs(R_pred - RT)}, {abs(G_pred - GT)}, {abs(B_pred - BT)})\")\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é˜¶æ®µ 1ï¼šå¢žå¼ºç³»æ•°ä¸Žè¿‘ä¼¼æ¡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- é˜¶æ®µ 1ï¼šå¢žå¼ºç³»æ•°ä¸Žè¿‘ä¼¼æ¡ä»¶ ----------\n",
    "def objective_stage1(trial):\n",
    "    low_bound = 80\n",
    "    mid_bound = 160\n",
    "    close_threshold = trial.suggest_int(\"close_threshold\", 1, 10)\n",
    "    enhance_coeffs = [trial.suggest_float(f\"enhance{i}\", 0.01, 0.8) for i in range(3)]\n",
    "    reduce_coeffs = [trial.suggest_float(f\"reduce{i}\", 0.01, 0.8) for i in range(3)]\n",
    "    thresholds = [83, 157, 234]  # å›ºå®š\n",
    "\n",
    "    # é»˜è®¤ R/G/B å‚æ•°\n",
    "    R_params = [1] + [0.189, 0.139, 0.232] + [0.25, 0.097, 0.205, 0.332]\n",
    "    G_params = [1] + [0.07, 0.04, 0.07] + [0.012, 0.123, 0.108, 0.051]\n",
    "    B_params = [1] + [0.042, 0.012, 0.24] + [0.123, 0.262, 0.278, 0.037]\n",
    "\n",
    "    params = (low_bound, mid_bound, close_threshold, enhance_coeffs, reduce_coeffs, thresholds,\n",
    "              tuple(R_params), tuple(G_params), tuple(B_params))\n",
    "    return compute_mae_and_smoothness(params)\n",
    "\n",
    "def run_stage1(n_trials=200):\n",
    "    study = optuna.create_study(directions=[\"minimize\"])\n",
    "    study.optimize(objective_stage1, n_trials=n_trials, show_progress_bar=True)\n",
    "    best = min(study.best_trials, key=lambda t: t.values[0])\n",
    "    print(f\"Best MAE: {best.values[0]}\")\n",
    "    save_best_params(best, \"less_param_multi_stage_save/stage1_params.csv\")\n",
    "    plot_history(study, \"stage1\")\n",
    "    print(\"âœ… é˜¶æ®µ 1 å®Œæˆ\")\n",
    "\n",
    "run_stage1(n_trials=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é˜¶æ®µ 2ï¼šé˜ˆå€¼å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- é˜¶æ®µ 2ï¼šé˜ˆå€¼å‚æ•° ----------\n",
    "def objective_stage2(trial):\n",
    "    p = load_params_from_json(\"less_param_multi_stage_save/stage1_params.json\")\n",
    "    \n",
    "    threshold0 = trial.suggest_int(\"threshold0\", 40, 120)\n",
    "    threshold1 = trial.suggest_int(\"threshold1\", threshold0 + 20, 200)\n",
    "    threshold2 = trial.suggest_int(\"threshold2\", threshold1 + 20, 255)\n",
    "    thresholds = [threshold0, threshold1, threshold2]\n",
    "    low_bound = trial.suggest_int(\"low_bound\", 40, 150)\n",
    "    mid_bound = trial.suggest_int(\"mid_bound\", low_bound + 50, 255)\n",
    "    close_threshold = p[\"close_threshold\"]\n",
    "    enhance_coeffs = [p[f\"enhance{i}\"] for i in range(3)]\n",
    "    reduce_coeffs = [p[f\"reduce{i}\"] for i in range(3)]\n",
    "\n",
    "    R_params = [1] + [0.189, 0.139, 0.232] + [0.25, 0.097, 0.205, 0.332]\n",
    "    G_params = [1] + [0.07, 0.04, 0.07] + [0.012, 0.123, 0.108, 0.051]\n",
    "    B_params = [1] + [0.042, 0.012, 0.24] + [0.123, 0.262, 0.278, 0.037]\n",
    "\n",
    "    params = (low_bound, mid_bound, close_threshold, enhance_coeffs, reduce_coeffs, thresholds,\n",
    "              tuple(R_params), tuple(G_params), tuple(B_params))\n",
    "    return compute_mae_and_smoothness(params)\n",
    "\n",
    "def run_stage2(n_trials=200):\n",
    "    print(\"ðŸš€ é˜¶æ®µ 2 å¼€å§‹\")\n",
    "    study = optuna.create_study(directions=[\"minimize\"])\n",
    "    study.optimize(objective_stage2, n_trials=n_trials, show_progress_bar=True)\n",
    "    best = min(study.best_trials, key=lambda t: t.values[0])\n",
    "    print(f\"Best MAE: {best.values[0]}\")\n",
    "    save_best_params(best, \"less_param_multi_stage_save/stage2_params.csv\")\n",
    "    plot_history(study, \"stage2\")\n",
    "    print(\"âœ… é˜¶æ®µ 2 å®Œæˆ\")\n",
    "\n",
    "run_stage2(n_trials=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é˜¶æ®µ 3ï¼šR/G/B å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- é˜¶æ®µ 3ï¼šR/G/B å‚æ•° ----------\n",
    "def objective_stage3(trial):\n",
    "    p = load_params_from_json(\"less_param_multi_stage_save/stage2_params.json\")\n",
    "    p1 = load_params_from_json(\"less_param_multi_stage_save/stage1_params.json\")\n",
    "    \n",
    "    thresholds = [p[f\"threshold{i}\"] for i in range(3)]\n",
    "    low_bound = p[\"low_bound\"]\n",
    "    mid_bound = p[\"mid_bound\"]\n",
    "    close_threshold = p1[\"close_threshold\"]\n",
    "    enhance_coeffs = [p1[f\"enhance{i}\"] for i in range(3)]\n",
    "    reduce_coeffs = [p1[f\"reduce{i}\"] for i in range(3)]\n",
    "\n",
    "    R_params = [1,\n",
    "        trial.suggest_float(\"R_enh1\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"R_enh2\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"R_enh3\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"R_red1\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"R_red2\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"R_red3\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"R_red4\", 0.01, 0.5)]\n",
    "\n",
    "    G_params = [1,\n",
    "        trial.suggest_float(\"G_enh1\", 0.01, 0.1),\n",
    "        trial.suggest_float(\"G_enh2\", 0.01, 0.1),\n",
    "        trial.suggest_float(\"G_enh3\", 0.01, 0.1),\n",
    "        trial.suggest_float(\"G_red1\", 0.01, 0.1),\n",
    "        trial.suggest_float(\"G_red2\", 0.01, 0.1),\n",
    "        trial.suggest_float(\"G_red3\", 0.01, 0.1),\n",
    "        trial.suggest_float(\"G_red4\", 0.01, 0.1)]\n",
    "\n",
    "    B_params = [1,\n",
    "        trial.suggest_float(\"B_enh1\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"B_enh2\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"B_enh3\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"B_red1\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"B_red2\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"B_red3\", 0.01, 0.5),\n",
    "        trial.suggest_float(\"B_red4\", 0.01, 0.5)]\n",
    "\n",
    "    params = (low_bound, mid_bound, close_threshold, enhance_coeffs, reduce_coeffs, thresholds,\n",
    "              tuple(R_params), tuple(G_params), tuple(B_params))\n",
    "    return compute_mae_and_smoothness(params)\n",
    "\n",
    "def run_stage3(n_trials=200):\n",
    "    print(\"ðŸš€ é˜¶æ®µ 3 å¼€å§‹\")\n",
    "    study = optuna.create_study(directions=[\"minimize\"])\n",
    "    study.optimize(objective_stage3, n_trials=n_trials, show_progress_bar=True)\n",
    "    best = min(study.best_trials, key=lambda t: t.values[0])\n",
    "    print(f\"Best MAE: {best.values[0]}\")\n",
    "    save_best_params(best, \"less_param_multi_stage_save/stage3_params.csv\")\n",
    "    plot_history(study, \"stage3\")\n",
    "    print(\"âœ… é˜¶æ®µ 3 å®Œæˆ\")\n",
    "\n",
    "run_stage3(n_trials=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é˜¶æ®µ 4ï¼šå…¨å±€å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- é˜¶æ®µ 4ï¼šå…¨å±€å¾®è°ƒ ----------\n",
    "def objective_stage4(trial):\n",
    "    p = load_params_from_json(\"less_param_multi_stage_save/stage3_params.json\")\n",
    "\n",
    "    p2 = load_params_from_json(\"less_param_multi_stage_save/stage2_params.json\")\n",
    "    p1 = load_params_from_json(\"less_param_multi_stage_save/stage1_params.json\")\n",
    "    def vary(name, base, scale):\n",
    "        return trial.suggest_float(name, base * (1 - scale), base * (1 + scale))\n",
    "\n",
    "    thresholds = [int(vary(f\"threshold{i}\", p2[f\"threshold{i}\"], 0.1)) for i in range(3)]\n",
    "    low_bound = int(vary(\"low_bound\", p2[\"low_bound\"], 0.1))\n",
    "    mid_bound = int(vary(\"mid_bound\", p2[\"mid_bound\"], 0.1))\n",
    "    close_threshold = int(vary(\"close_threshold\", p1[\"close_threshold\"], 0.2))\n",
    "    enhance_coeffs = [vary(f\"enhance{i}\", p1[f\"enhance{i}\"], 0.2) for i in range(3)]\n",
    "    reduce_coeffs = [vary(f\"reduce{i}\", p1[f\"reduce{i}\"], 0.2) for i in range(3)]\n",
    "\n",
    "    R_params = [1] + [vary(f\"R_enh{i+1}\", p[f\"R_enh{i+1}\"], 0.2) for i in range(3)] + \\\n",
    "               [vary(f\"R_red{i+1}\", p[f\"R_red{i+1}\"], 0.2) for i in range(4)]\n",
    "    G_params = [1] + [vary(f\"G_enh{i+1}\", p[f\"G_enh{i+1}\"], 0.2) for i in range(3)] + \\\n",
    "               [vary(f\"G_red{i+1}\", p[f\"G_red{i+1}\"], 0.2) for i in range(4)]\n",
    "    B_params = [1] + [vary(f\"B_enh{i+1}\", p[f\"B_enh{i+1}\"], 0.2) for i in range(3)] + \\\n",
    "               [vary(f\"B_red{i+1}\", p[f\"B_red{i+1}\"], 0.2) for i in range(4)]\n",
    "\n",
    "    params = (low_bound, mid_bound, close_threshold, enhance_coeffs, reduce_coeffs, thresholds,\n",
    "              tuple(R_params), tuple(G_params), tuple(B_params))\n",
    "    return compute_mae_and_smoothness(params)\n",
    "\n",
    "def run_stage4(n_trials=200):\n",
    "    print(\"ðŸš€ é˜¶æ®µ 4 å¼€å§‹\")\n",
    "    study = optuna.create_study(directions=[\"minimize\"])\n",
    "    study.optimize(objective_stage4, n_trials=n_trials, show_progress_bar=True)\n",
    "    best = min(study.best_trials, key=lambda t: t.values[0])\n",
    "    print(f\"Best MAE: {best.values[0]}\")\n",
    "    save_best_params(best, \"less_param_multi_stage_save/stage4_params.csv\")\n",
    "    plot_history(study, \"stage4\")\n",
    "    print(\"âœ… é˜¶æ®µ 4 å®Œæˆ\")\n",
    "\n",
    "run_stage4(n_trials=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### æ ·ä¾‹æµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # å¢žåŠ è®¡ç®—å¹³å‡ MAD çš„åŠŸèƒ½å¹¶è¾“å‡º\n",
    "best_params_for_analysis = load_params_from_json('less_param_multi_stage_save/stage4_params.json')\n",
    "print_predictions(best_params_for_analysis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
